{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "  import xml.etree.cElementTree as et\n",
    "except ImportError:\n",
    "  import xml.etree.ElementTree as et\n",
    "import numpy as np   \n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "K_DEPTH_VIEW = 30\n",
    "K_DEPTH_SAT = 10\n",
    "MAX_REL = 5\n",
    "MED_REL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Parse THUIR1\n",
    "'''\n",
    "DATA_DIR = \"THUIR1/search_sessions/\"\n",
    "SCORE_FILE=\"THUIR1/metrics.txt\"\n",
    "REL_FILE = \"THUIR1/relevance.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_log = []\n",
    "ss = [] # score list\n",
    "rels = [] # relevance list\n",
    "\n",
    "with open (SCORE_FILE, 'r+', encoding = 'utf-8') as f:\n",
    "    ss = [i[:-1].split('\\t') for i in f.readlines()]\n",
    "    \n",
    "with open (REL_FILE, 'r+', encoding = 'utf-8') as f:\n",
    "    rels = [i[:-1].split('\\t') for i in f.readlines()]\n",
    "\n",
    "for rec in ss:\n",
    "    sat = -1\n",
    "    session_id = rec[0]\n",
    "    serp_id = session_id.split('_')[1]\n",
    "    cl = [] # click list\n",
    "    \n",
    "    # Parse log\n",
    "    #print(session_id)\n",
    "    try:\n",
    "        with open (DATA_DIR+session_id, 'r+', encoding = 'utf-8') as f:\n",
    "            for i in f.readlines():\n",
    "                l = i[:-1].split('\\t')\n",
    "                if l[2] == 'ACTION=SATISFY':\n",
    "                    # Extract satisfaction score\n",
    "                    sat = float(l[4][-1])\n",
    "                if l[2] == 'ACTION=CLICK':\n",
    "                    # Extract distinct click record\n",
    "                    c = int(l[5][-1])\n",
    "                    if c not in cl:\n",
    "                        cl.append(c)             \n",
    "    except:\n",
    "        continue\n",
    "    nc = len(cl)\n",
    "    if nc:\n",
    "        dc = max(cl) + 1\n",
    "    else:\n",
    "        dc = 0\n",
    "    query_result = []\n",
    "    for rel in rels:\n",
    "        if rel[0] == serp_id:\n",
    "            for rank in range(0,10):\n",
    "                query_result.append({'doc_id':serp_id + str(rank), 'doc_rank': str(rank), 'doc_rel': str(rel[rank+1])})\n",
    "    \n",
    "    \n",
    "    parsed_log.append({'id':session_id, 'result':query_result, 'sat': str(sat), 'nc': str(nc), 'dc': str(dc)})       \n",
    "\n",
    "\n",
    "print(len(parsed_log))\n",
    "print(parsed_log[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_insq(x):\n",
    "    res = 0\n",
    "    for i in range(1, x+1):\n",
    "        res += 1/i**2\n",
    "    return math.pi**2 / 6 - res\n",
    "\n",
    "def gain(rel):\n",
    "    return rel\n",
    "\n",
    "def gain_err(rel):\n",
    "    return (2**rel - 1)/2**MAX_REL\n",
    "\n",
    "# The probability users view the document at rank n\n",
    "# Supposed they always view the first document\n",
    "def decay_dcg (b, n):\n",
    "    return 1.0/(1+ math.log(n,b))\n",
    "\n",
    "def v_rbp(p, n):\n",
    "    return p**(n-1)\n",
    "\n",
    "def v_insq(t, n, last_prob):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return last_prob * ((n + 2*t - 2)/(n + 2*t -1))**2\n",
    "    \n",
    "def v_inst(t, n, cr, last_prob):\n",
    "    if last_prob <= 0:\n",
    "        return 0\n",
    "    \n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        tn = t - cr\n",
    "        v = last_prob * ((n + t + tn - 2)/(n + t + tn - 1))**2\n",
    "        if v > 0:\n",
    "            return v\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def w_rbp(p, n):\n",
    "    return (1-p) * (p**(n-1))\n",
    "\n",
    "def w_err(rank, last_prob):\n",
    "    return (1.0/rank) * last_prob\n",
    "\n",
    "def w_p():\n",
    "    return 1/K_DEPTH_SAT \n",
    "\n",
    "def w_insq(t, n):\n",
    "    return (1/s_insq(2*t-1)) * (1/(n + 2*t - 1)**2)\n",
    "\n",
    "def w_inst(t, n, cr):\n",
    "    w = 1/(s_insq(2*t-1))*(1/(n + 2*t - cr -1)**2)\n",
    "    if w > 0:\n",
    "         return w\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCG_MODE = {'BEHAVIOUR':'ub', 'SATISFACTION':'us'}\n",
    "RBP_MODE = {'BEHAVIOUR':'ub', 'SATISFACTION':'us'}\n",
    "INSQ_MODE = {'BEHAVIOUR':'ub', 'SATISFACTION':'us'}\n",
    "INST_MODE = {'BEHAVIOUR':'ub', 'SATISFACTION':'us'}\n",
    "METRIC = {'DCG':'dcg', 'RBP':'rbp', 'ERR':'err', 'P':'p', 'INSQ':'insq', 'INST':'inst'}\n",
    "\n",
    "'''\n",
    "RQ1 - How to issue a new framework incorporating the anchoring effect into IR metrics\n",
    "'''\n",
    "\n",
    "def default_run(pm, result_list, metric):\n",
    "    if metric not in METRIC:\n",
    "        raise Exception('No such metric: %s'%(metric))\n",
    "    res = 0\n",
    "    last_prob = 1.0 # For ERR\n",
    "    cr = 0 # For INST\n",
    "    for doc in result_list:\n",
    "        if int(doc['doc_rank'])< K_DEPTH_SAT:\n",
    "            cur_rel = float(doc['doc_rel'])\n",
    "            cur_rank = int(doc['doc_rank'])+1\n",
    "            if metric == 'DCG':\n",
    "                cur_gain = gain(cur_rel)*decay_dcg(pm, cur_rank)\n",
    "            elif metric == 'RBP':\n",
    "                cur_gain = gain(cur_rel)*w_rbp(pm, cur_rank)\n",
    "            elif metric == 'ERR':\n",
    "                cur_gain = gain_err(cur_rel)*w_err(cur_rank, last_prob)\n",
    "                last_prob *= 1- cur_gain\n",
    "            elif metric == 'P':\n",
    "                cur_gain = gain(cur_rel)*w_p()\n",
    "            elif metric == 'INSQ':\n",
    "                cur_gain = gain(cur_rel) * w_insq(pm, cur_rank)\n",
    "            elif metric == 'INST':\n",
    "                cur_gain = gain(cur_rel) * w_inst(pm, cur_rank, cr)\n",
    "                cr += cur_rel/MAX_REL\n",
    "            res += cur_gain\n",
    "    return res\n",
    "\n",
    "def AEM_run(pm, l, k,result_list, metric):\n",
    "    if metric not in METRIC:\n",
    "        raise Exception('No such metric: %s'%(metric))\n",
    "    res = 0.0\n",
    "    last_rel = -1.0\n",
    "    # For ERR\n",
    "    last_prob = 1.0\n",
    "    # For INST\n",
    "    cr = 0\n",
    "    for doc in result_list:\n",
    "        cur_rank = int(doc['doc_rank']) + 1\n",
    "        if cur_rank <= K_DEPTH_SAT:\n",
    "            # First doc\n",
    "            if cur_rank == 1:\n",
    "                cur_rel = float(doc['doc_rel'])\n",
    "            else:\n",
    "                x = (last_rel - MED_REL)/(MAX_REL-MED_REL)\n",
    "                a = l / (k + math.exp(-(1/k)*(x)))\n",
    "                if a > l:\n",
    "                    a = l\n",
    "                cur_rel = a*last_rel + (1-a)*float(doc['doc_rel'])\n",
    "                \n",
    "            # We assume that users assess documents objectively, \n",
    "            # but their gain from the current document is affected by the quality of the last document\n",
    "            if metric == 'DCG':\n",
    "                cur_gain = gain(cur_rel)*decay_dcg(pm, cur_rank)\n",
    "            elif metric == 'RBP':\n",
    "                cur_gain = gain(cur_rel)*w_rbp(pm, cur_rank)\n",
    "            elif metric == 'ERR':\n",
    "                cur_gain = gain_err(cur_rel)*w_err(cur_rank, last_prob)\n",
    "                last_prob *= (1- cur_gain)\n",
    "            elif metric == 'P':\n",
    "                cur_gain =  gain(cur_rel)*w_p()\n",
    "            elif metric == 'INSQ':\n",
    "                cur_gain = gain(cur_rel) * w_insq(pm, cur_rank)\n",
    "            elif metric == 'INST':\n",
    "                cur_gain = gain(cur_rel)*w_inst(pm, cur_rank, cr)\n",
    "                cr += cur_rel/MAX_REL\n",
    "        else:\n",
    "            break\n",
    "        res += cur_gain\n",
    "        # Real Quality\n",
    "        last_rel = float(doc['doc_rel'])\n",
    "    #print(res)\n",
    "    return res\n",
    "        \n",
    "def compute_TSE(train_set, metric, pm):\n",
    "    if metric not in METRIC:\n",
    "        raise Exception('No such metric: %s'%(metric))\n",
    "    tse = 0\n",
    "    last_prob = 1 # For INSQ & INST\n",
    "    cr = 0 # For INST\n",
    "    for q in train_set:\n",
    "        dc = int(q['dc'])\n",
    "        nc = int(q['nc'])\n",
    "        for rank in range(1, K_DEPTH_VIEW+1):\n",
    "            if metric == 'DCG':\n",
    "                p_dr_hat = decay_dcg(pm, rank)\n",
    "            elif metric == 'RBP':\n",
    "                p_dr_hat = v_rbp(pm, rank)\n",
    "            elif metric == 'INSQ':\n",
    "                p_dr_hat = v_insq(pm, rank, last_prob)\n",
    "                last_prob *= p_dr_hat\n",
    "            # We assume that the relevance of documents \n",
    "            # at depth larger than assessment depth is 0\n",
    "            elif metric == 'INST':\n",
    "                if rank <= K_DEPTH_SAT:\n",
    "                    cur_rel = float(q['result'][rank-1]['doc_rel'])\n",
    "                else:\n",
    "                    cur_rel = 0\n",
    "                p_dr_hat = v_inst(pm, rank, cr, last_prob)\n",
    "                last_prob *= p_dr_hat\n",
    "                cr += cur_rel/MAX_REL\n",
    "                \n",
    "            if rank <= dc:\n",
    "                p_dr = 1\n",
    "            else:\n",
    "                n = rank - dc\n",
    "                #k = 5.1 + dc* 0.29 - nc*0.14 # Wickasono(2021) Model2\n",
    "                k = 3.48 - dc* 0.46 + nc * 0.2  # Wickasono(2020) for THUIR1\n",
    "                if(k < 0):\n",
    "                    p_dr = 0\n",
    "                else:\n",
    "                    p_dr = math.exp((-1.0*n)/k)\n",
    "            tse += (p_dr_hat - p_dr)**2\n",
    "            \n",
    "    return tse\n",
    "        \n",
    "'''\n",
    "Grid Search for DCG\n",
    "'''\n",
    "def train_dcg_baseline(train_set, mode):\n",
    "    if mode not in DCG_MODE:\n",
    "        raise Exception('No such mode: %s'%(mode))\n",
    "    \n",
    "    dcg_b={}   \n",
    "    for b in np.arange(1.1, 5.01, 0.1):\n",
    "        b = round(b, 2)\n",
    "        if mode == 'BEHAVIOUR':\n",
    "            dcg_b[b] = compute_TSE(train_set, 'DCG', b)\n",
    "        elif mode == 'SATISFACTION':\n",
    "            Y = [float(q['sat']) for q in train_set]\n",
    "            X = [default_run(b, q['result'],  'DCG') for q in train_set]\n",
    "            dcg_b[b] = scipy.stats.spearmanr(X, Y).correlation\n",
    "    \n",
    "    if mode == 'BEHAVIOUR':\n",
    "        b_st = min(dcg_b, key = dcg_b.get)\n",
    "    elif mode == 'SATISFACTION':\n",
    "        b_st = max(dcg_b, key = dcg_b.get)\n",
    "        \n",
    "    return b_st\n",
    "\n",
    "\n",
    "'''\n",
    "Grid Search for RBP\n",
    "'''\n",
    "def train_rbp_baseline(train_set, mode):\n",
    "    if mode not in RBP_MODE:\n",
    "        raise Exception('No such mode: %s'%(mode))\n",
    "        \n",
    "    rbp_p = {}\n",
    "    for p in np.arange(0, 1.01, 0.05):\n",
    "        p = round(p, 2)\n",
    "        if mode == 'BEHAVIOUR':\n",
    "            rbp_p[p] = compute_TSE(train_set, 'RBP', p)\n",
    "        elif mode == 'SATISFACTION':\n",
    "            Y = [float(q['sat']) for q in train_set]\n",
    "            X = [default_run(p, q['result'], 'RBP') for q in train_set]\n",
    "            rbp_p[p] = scipy.stats.spearmanr(X, Y).correlation\n",
    "            \n",
    "    if mode == 'BEHAVIOUR':\n",
    "        p_st = min(rbp_p, key = rbp_p.get)\n",
    "    elif mode == 'SATISFACTION':\n",
    "        p_st = max(rbp_p, key = rbp_p.get)\n",
    "        \n",
    "    return p_st\n",
    "        \n",
    "'''\n",
    "Grid Search for INSQ\n",
    "'''\n",
    "def train_insq_baseline(train_set, mode):\n",
    "    if mode not in INSQ_MODE:\n",
    "        raise Exception('No such mode: %s'%(mode))\n",
    "        \n",
    "    insq_t = {}\n",
    "    for t in range(1, 25):\n",
    "        if mode == 'BEHAVIOUR':\n",
    "            insq_t[t] = compute_TSE(train_set, 'INSQ', t)\n",
    "        elif mode == 'SATISFACTION':\n",
    "            Y = [float(q['sat']) for q in train_set]\n",
    "            X = [default_run(t, q['result'], 'INSQ') for q in train_set]\n",
    "            insq_t[t] = scipy.stats.spearmanr(X, Y).correlation\n",
    "            \n",
    "    if mode == 'BEHAVIOUR':\n",
    "        t_st = min(insq_t, key = insq_t.get)\n",
    "    elif mode == 'SATISFACTION':\n",
    "        t_st = max(insq_t, key = insq_t.get)\n",
    "        \n",
    "    return t_st\n",
    "\n",
    "        \n",
    "'''\n",
    "Grid Search for INST\n",
    "'''\n",
    "def train_inst_baseline(train_set, mode):\n",
    "    if mode not in INST_MODE:\n",
    "        raise Exception('No such mode: %s'%(mode))\n",
    "        \n",
    "    inst_t = {}\n",
    "    for t in range(1, 25):\n",
    "        if mode == 'BEHAVIOUR':\n",
    "            inst_t[t] = compute_TSE(train_set, 'INST', t)\n",
    "        elif mode == 'SATISFACTION':\n",
    "            Y = [float(q['sat']) for q in train_set]\n",
    "            X = [default_run(t, q['result'], 'INST') for q in train_set]\n",
    "            inst_t[t] = scipy.stats.spearmanr(X, Y).correlation\n",
    "            \n",
    "    if mode == 'BEHAVIOUR':\n",
    "        t_st = min(inst_t, key = inst_t.get)\n",
    "    elif mode == 'SATISFACTION':\n",
    "        t_st = max(inst_t, key = inst_t.get)\n",
    "        \n",
    "    return t_st\n",
    "\n",
    "'''\n",
    "Grid Search for Callibrating lambda and kappa for AEMs\n",
    "'''\n",
    "\n",
    "def train_AEM(pm, train_set, metric):\n",
    "    if metric not in METRIC:\n",
    "        raise Exception('No such metric: %s'%(metric))\n",
    "    map_aem = {}\n",
    "    Y = [float(q['sat']) for q in train_set]\n",
    "    for l in np.arange(0, 1.01, 0.1):\n",
    "        l = round(l, 3)\n",
    "        for k in np.arange(0, 0.501, 0.05):\n",
    "            k = round(k, 4)\n",
    "            if metric == 'DCG':\n",
    "                X = [AEM_run(pm, l, k, q['result'], 'DCG') for q in train_set]\n",
    "            elif metric == 'RBP':\n",
    "                X = [AEM_run(pm, l, k, q['result'], 'RBP') for q in train_set]\n",
    "            elif metric == 'ERR':\n",
    "                X =  [AEM_run(pm, l, k, q['result'], 'ERR') for q in train_set]\n",
    "            elif metric == 'P':\n",
    "                X =  [AEM_run(pm, l, k, q['result'], 'P') for q in train_set]\n",
    "            elif metric == 'INSQ':\n",
    "                X =  [AEM_run(pm, l, k, q['result'], 'INSQ') for q in train_set]\n",
    "            elif metric == 'INST':\n",
    "                X =  [AEM_run(pm, l, k, q['result'], 'INST') for q in train_set]\n",
    "            if not(l in map_aem):\n",
    "                map_aem[l] = {}\n",
    "            map_aem[l][k] = scipy.stats.spearmanr(X, Y).correlation\n",
    "    # Find best parameter   \n",
    "    r = -1\n",
    "    l_st = -1\n",
    "    k_st = -1\n",
    "    for l in map_aem:\n",
    "        for k in map_aem[l]:\n",
    "            if map_aem[l][k] > r:\n",
    "                r = map_aem[l][k]\n",
    "                l_st = l\n",
    "                k_st = k\n",
    "    return (l_st, k_st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_dcg_b = []\n",
    "rl_dcg_s = []\n",
    "rl_dcg_AEM = []\n",
    "\n",
    "rl_rbp_b = []\n",
    "rl_rbp_s = []\n",
    "rl_rbp_AEM = []\n",
    "\n",
    "rl_err = []\n",
    "rl_err_AEM = []\n",
    "\n",
    "rl_p = []\n",
    "rl_p_AEM = []\n",
    "\n",
    "rl_insq_b = []\n",
    "rl_insq_s = []\n",
    "rl_insq_AEM = []\n",
    "\n",
    "rl_inst_b = []\n",
    "rl_inst_s = []\n",
    "rl_inst_AEM = []\n",
    "\n",
    "l1s = []\n",
    "k1s = []\n",
    "bbs = []\n",
    "bss = []\n",
    "\n",
    "l2s = []\n",
    "k2s = []\n",
    "pbs = []\n",
    "pss = []\n",
    "\n",
    "l3s = []\n",
    "k3s = []\n",
    "\n",
    "l4s = []\n",
    "k4s = []\n",
    "\n",
    "l5s = []\n",
    "k5s = []\n",
    "t1bs = []\n",
    "t1ss = []\n",
    "\n",
    "l6s = []\n",
    "k6s = []\n",
    "t2bs = []\n",
    "t2ss = []\n",
    "\n",
    "tt = 0\n",
    "\n",
    "for i in range(0, 10):\n",
    "    kf = KFold(n_splits=5,shuffle=True)\n",
    "    for train_index , test_index in kf.split(parsed_log): \n",
    "        tt+=1\n",
    "        print('training: %s'%(tt))\n",
    "        train_set = [parsed_log[i] for i in train_index]\n",
    "        test_set = [parsed_log[i] for i in test_index]\n",
    "\n",
    "        b_b = train_dcg_baseline(train_set, 'BEHAVIOUR')\n",
    "        b_s = train_dcg_baseline(train_set, 'SATISFACTION')\n",
    "        l_1, k_1 = train_AEM(b_b, train_set, 'DCG')\n",
    "        l1s.append(l_1)\n",
    "        k1s.append(k_1)\n",
    "        bbs.append(b_b)\n",
    "        bss.append(b_s)\n",
    "        \n",
    "        p_b = train_rbp_baseline(train_set, 'BEHAVIOUR')\n",
    "        p_s = train_rbp_baseline(train_set, 'SATISFACTION')\n",
    "        l_2, k_2 = train_AEM(p_b, train_set, 'RBP')\n",
    "        l2s.append(l_2)\n",
    "        k2s.append(k_2)\n",
    "        pbs.append(p_b)\n",
    "        pss.append(p_s)\n",
    "        \n",
    "        l_3, k_3 = train_AEM(-1, train_set, 'ERR')\n",
    "        l3s.append(l_3)\n",
    "        k3s.append(k_3)\n",
    "        \n",
    "        l_4, k_4 = train_AEM(-1, train_set, 'P')\n",
    "        l4s.append(l_4)\n",
    "        k4s.append(k_4)\n",
    "        \n",
    "        t1_b = train_insq_baseline(train_set, 'BEHAVIOUR')\n",
    "        t1_s = train_insq_baseline(train_set, 'SATISFACTION')\n",
    "        l_5, k_5 = train_AEM(t1_b, train_set, 'INSQ')\n",
    "        l5s.append(l_5)\n",
    "        k5s.append(k_5)\n",
    "        t1bs.append(t1_b)\n",
    "        t1ss.append(t1_s)\n",
    "        \n",
    "        t2_b = train_inst_baseline(train_set, 'BEHAVIOUR')\n",
    "        t2_s = train_inst_baseline(train_set, 'SATISFACTION')\n",
    "        l_6, k_6 = train_AEM(t2_b, train_set, 'INST')\n",
    "        l6s.append(l_6)\n",
    "        k6s.append(k_6)\n",
    "        t2bs.append(t2_b)\n",
    "        t2ss.append(t2_s)\n",
    "        \n",
    "        X_dcg_b = [default_run(b_b, q['result'], 'DCG') for q in test_set]\n",
    "        X_dcg_s = [default_run(b_s, q['result'], 'DCG') for q in test_set]\n",
    "        X_dcg_AEM = [AEM_run(b_b, l_1 , k_1, q['result'], 'DCG') for q in test_set]\n",
    "        \n",
    "        X_rbp_b = [default_run(p_b, q['result'], 'RBP') for q in test_set]\n",
    "        X_rbp_s = [default_run(p_s, q['result'], 'RBP') for q in test_set]\n",
    "        X_rbp_AEM = [AEM_run(p_b, l_2 , k_2, q['result'], 'RBP') for q in test_set]\n",
    "        \n",
    "        X_err = [default_run(-1, q['result'], 'ERR')  for q in test_set]\n",
    "        X_err_AEM = [AEM_run(-1, l_3 , k_3, q['result'], 'ERR') for q in test_set]\n",
    "        \n",
    "        X_p = [default_run(-1, q['result'], 'P')  for q in test_set]\n",
    "        X_p_AEM = [AEM_run(-1, l_4 , k_4, q['result'], 'P') for q in test_set]\n",
    "        \n",
    "        X_insq_b = [default_run(t1_b, q['result'], 'INSQ') for q in test_set]\n",
    "        X_insq_s = [default_run(t1_s, q['result'], 'INSQ') for q in test_set]\n",
    "        X_insq_AEM = [AEM_run(t1_b, l_5 , k_5, q['result'], 'INSQ') for q in test_set]\n",
    "        \n",
    "        X_inst_b = [default_run(t2_b, q['result'], 'INST') for q in test_set]\n",
    "        X_inst_s = [default_run(t2_s, q['result'], 'INST') for q in test_set]\n",
    "        X_inst_AEM = [AEM_run(t2_b, l_6 , k_6, q['result'], 'INST') for q in test_set]\n",
    "        \n",
    "        Y = [float(q['sat']) for q in test_set]\n",
    "        \n",
    "        rl_dcg_b.append(scipy.stats.spearmanr(X_dcg_b, Y).correlation)\n",
    "        rl_dcg_s.append(scipy.stats.spearmanr(X_dcg_s, Y).correlation)\n",
    "        rl_dcg_AEM.append(scipy.stats.spearmanr(X_dcg_AEM, Y).correlation)\n",
    "        print(\"DCG b_b=%3f b_s = %3f b-rel=%4f s-rel=%4f\"%(b_b, b_s, scipy.stats.spearmanr(X_dcg_b, Y).correlation, scipy.stats.spearmanr(X_dcg_s, Y).correlation))\n",
    "        print(\"AEM-DCG lambda=%3f, kappa=%3f rel=%4f\"%(l_1, k_1, scipy.stats.spearmanr(X_dcg_AEM, Y).correlation))\n",
    "    \n",
    "        rl_rbp_b.append(scipy.stats.spearmanr(X_rbp_b, Y).correlation)\n",
    "        rl_rbp_s.append(scipy.stats.spearmanr(X_rbp_s, Y).correlation)\n",
    "        rl_rbp_AEM.append(scipy.stats.spearmanr(X_rbp_AEM, Y).correlation)\n",
    "        print(\"RBP p_b=%3f, p_s=%3f b-rel=%4f s-rel=%4f\"%(p_b, p_s, scipy.stats.spearmanr(X_rbp_b, Y).correlation, scipy.stats.spearmanr(X_rbp_s, Y).correlation))\n",
    "        print(\"AEM-RBP lambda=%3f, kappa=%3f rel=%4f\"%(l_2, k_2, scipy.stats.spearmanr(X_rbp_AEM, Y).correlation))\n",
    "        \n",
    "        rl_err.append(scipy.stats.spearmanr(X_err, Y).correlation)\n",
    "        rl_err_AEM.append(scipy.stats.spearmanr(X_err_AEM, Y).correlation)\n",
    "        print(\"ERR rel=%4f\"%(scipy.stats.spearmanr(X_err, Y).correlation))\n",
    "        print(\"AEM-ERR lambda=%3f, kappa=%3f rel=%4f\"%(l_3, k_3, scipy.stats.spearmanr(X_err_AEM, Y).correlation))\n",
    "        \n",
    "        rl_p.append(scipy.stats.spearmanr(X_p, Y).correlation)\n",
    "        rl_p_AEM.append(scipy.stats.spearmanr(X_p_AEM, Y).correlation)\n",
    "        print(\"Prec rel=%4f\"%(scipy.stats.spearmanr(X_p, Y).correlation))\n",
    "        print(\"AEM-Prec lambda=%3f, kappa=%3f rel=%4f\"%(l_4, k_4, scipy.stats.spearmanr(X_p_AEM, Y).correlation))\n",
    "        \n",
    "        rl_insq_b.append(scipy.stats.spearmanr(X_insq_b, Y).correlation)\n",
    "        rl_insq_s.append(scipy.stats.spearmanr(X_insq_s, Y).correlation)\n",
    "        rl_insq_AEM.append(scipy.stats.spearmanr(X_insq_AEM, Y).correlation)\n",
    "        print(\"INSQ t_b=%3f t_s = %3f b-rel=%4f s-rel=%4f\"%(t1_b, t1_s, scipy.stats.spearmanr(X_insq_b, Y).correlation, scipy.stats.spearmanr(X_insq_s, Y).correlation))\n",
    "        print(\"AEM-INSQ lambda=%3f, kappa=%3f rel=%4f\"%(l_5, k_5, scipy.stats.spearmanr(X_insq_AEM, Y).correlation))\n",
    "        \n",
    "        rl_inst_b.append(scipy.stats.spearmanr(X_inst_b, Y).correlation)\n",
    "        rl_inst_s.append(scipy.stats.spearmanr(X_inst_s, Y).correlation)\n",
    "        rl_inst_AEM.append(scipy.stats.spearmanr(X_inst_AEM, Y).correlation)\n",
    "        print(\"INST t_b=%3f t_s = %3f b-rel=%4f s-rel=%4f\"%(t2_b, t2_s, scipy.stats.spearmanr(X_inst_b, Y).correlation, scipy.stats.spearmanr(X_inst_s, Y).correlation))\n",
    "        print(\"AEM-INST lambda=%3f, kappa=%3f rel=%4f\"%(l_6, k_6, scipy.stats.spearmanr(X_inst_AEM, Y).correlation))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_dcg_b = pd.Series(rl_dcg_b)\n",
    "rl_dcg_s = pd.Series(rl_dcg_s)\n",
    "rl_dcg_AEM = pd.Series(rl_dcg_AEM)\n",
    "\n",
    "rl_rbp_b = pd.Series(rl_rbp_b)\n",
    "rl_rbp_s = pd.Series(rl_rbp_s)\n",
    "rl_rbp_AEM = pd.Series(rl_rbp_AEM)\n",
    "\n",
    "rl_err = pd.Series(rl_err)\n",
    "rl_err_AEM = pd.Series(rl_err_AEM)\n",
    "\n",
    "rl_p = pd.Series(rl_p)\n",
    "rl_p_AEM = pd.Series(rl_p_AEM)\n",
    "\n",
    "rl_insq_b = pd.Series(rl_insq_b)\n",
    "rl_insq_s = pd.Series(rl_insq_s)\n",
    "rl_insq_AEM = pd.Series(rl_insq_AEM)\n",
    "\n",
    "rl_inst_b = pd.Series(rl_inst_b)\n",
    "rl_inst_s = pd.Series(rl_inst_s)\n",
    "rl_inst_AEM = pd.Series(rl_inst_AEM)\n",
    "\n",
    "l1s = pd.Series(l1s)\n",
    "k1s = pd.Series(k1s)\n",
    "bbs = pd.Series(bbs)\n",
    "bss =  pd.Series(bss)\n",
    "\n",
    "l2s = pd.Series(l2s)\n",
    "k2s = pd.Series(k2s)\n",
    "pbs =  pd.Series(pbs)\n",
    "pss =  pd.Series(pss)\n",
    "\n",
    "l3s = pd.Series(l3s)\n",
    "k3s = pd.Series(k3s)\n",
    "\n",
    "l4s = pd.Series(l4s)\n",
    "k4s = pd.Series(k4s)\n",
    "\n",
    "l5s = pd.Series(l5s)\n",
    "k5s = pd.Series(k5s)\n",
    "t1bs = pd.Series(t1bs)\n",
    "t1ss =  pd.Series(t1ss)\n",
    "\n",
    "l6s = pd.Series(l6s)\n",
    "k6s = pd.Series(k6s)\n",
    "t2bs = pd.Series(t2bs)\n",
    "t2ss =  pd.Series(t2ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "b_b Mean: 1.900    Std:0.000    DCG_UB Mean: 0.335    Std:0.041      \n",
      "############\n",
      "b_s Mean: 1.522    Std:0.082    DCG_US Mean: 0.336     Std:0.041       \n",
      "############\n",
      "lambda Mean: 1.000    Std:0.000    kappa Mean: 0.211    Std:0.055    AEM_DCG Mean: 0.361     Std:0.0396\n",
      "############\n",
      "stat=-3.213, p=0.0018\n",
      "stat=-3.142, p=0.0022\n",
      "############\n",
      "p_b Mean: 0.850    Std:0.000    RBP_UB Mean: 0.326     Std:0.041    \n",
      "############\n",
      "p_s Mean: 0.750    Std:0.000    RBP_US Mean: 0.340     Std:0.038   \n",
      "############\n",
      "lambda Mean: 1.000    Std:0.000    kappa Mean: 0.388    Std:0.116    AEM_RBP Mean: 0.360     Std:0.0385\n",
      "############\n",
      "stat=-4.281, p=0.0000\n",
      "stat=-2.626, p=0.0100\n",
      "############\n",
      "ERR Mean: 0.359     Std:0.037\n",
      "############\n",
      "lambda Mean: 0.844    Std:0.348    kappa Mean: 0.098    Std:0.030    AEM_ERR Mean: 0.358     Std:0.0383\n",
      "############\n",
      "stat=0.121, p=0.9043\n",
      "############\n",
      "Prec Mean: 0.263     Std:0.047\n",
      "############\n",
      "lambda Mean: 1.000    Std:0.000    kappa Mean: 0.319    Std:0.025    AEM_Prec Mean: 0.324     Std:0.0424\n",
      "############\n",
      "stat=-6.879, p=0.0000\n",
      "############\n",
      "t_b Mean: 3.760    Std:0.960    INSQ_UB Mean: 0.330     Std:0.041    \n",
      "############\n",
      "t_s Mean: 2.240    Std:0.431    INSQ_US Mean: 0.336     Std:0.039   \n",
      "############\n",
      "lambda Mean: 1.000    Std:0.000    kappa Mean: 0.276    Std:0.183    AEM_INSQ Mean: 0.358     Std:0.0389\n",
      "############\n",
      "stat=-3.501, p=0.0007\n",
      "stat=-2.863, p=0.0051\n",
      "############\n",
      "t_b Mean: 4.740    Std:0.876    INST_UB Mean: 0.317     Std:0.042    \n",
      "############\n",
      "t_s Mean: 1.100    Std:0.303    INST_US Mean: 0.336     Std:0.038   \n",
      "############\n",
      "lambda Mean: 1.000    Std:0.000    kappa Mean: 0.408    Std:0.093    AEM_INST Mean: 0.356     Std:0.0390\n",
      "############\n",
      "stat=-4.760, p=0.0000\n",
      "stat=-2.585, p=0.0112\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RQ2 - The peformance of AEMs compared with SOTA metrics\n",
    "'''\n",
    "\n",
    "print('############')\n",
    "print('b_b Mean: %.3f    Std:%.3f    DCG_UB Mean: %.3f    Std:%.3f      '%(bbs.mean(), bbs.std(), rl_dcg_b.mean(), rl_dcg_b.std())) \n",
    "print('############')\n",
    "print('b_s Mean: %.3f    Std:%.3f    DCG_US Mean: %.3f     Std:%.3f       '%(bss.mean(), bss.std(), rl_dcg_s.mean(), rl_dcg_s.std())) \n",
    "print('############')\n",
    "print('lambda Mean: %.3f    Std:%.3f    kappa Mean: %.3f    Std:%.3f    AEM_DCG Mean: %.3f     Std:%.4f'%(l1s.mean(), l1s.std(), k1s.mean(), k1s.std(), rl_dcg_AEM.mean(), rl_dcg_AEM.std()))\n",
    "print('############')\n",
    "stat, p = scipy.stats.ttest_ind(rl_dcg_b, rl_dcg_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "stat, p = scipy.stats.ttest_ind(rl_dcg_s, rl_dcg_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "\n",
    "print('############')\n",
    "print('p_b Mean: %.3f    Std:%.3f    RBP_UB Mean: %.3f     Std:%.3f    '%(pbs.mean(), pbs.std(),rl_rbp_b.mean(), rl_rbp_b.std())) \n",
    "print('############')\n",
    "print('p_s Mean: %.3f    Std:%.3f    RBP_US Mean: %.3f     Std:%.3f   '%(pss.mean(), pss.std(), rl_rbp_s.mean(), rl_rbp_s.std())) \n",
    "print('############')\n",
    "print('lambda Mean: %.3f    Std:%.3f    kappa Mean: %.3f    Std:%.3f    AEM_RBP Mean: %.3f     Std:%.4f'%(l2s.mean(), l2s.std(), k2s.mean(), k2s.std(), rl_rbp_AEM.mean(), rl_rbp_AEM.std())) \n",
    "print('############')\n",
    "stat, p = scipy.stats.ttest_ind(rl_rbp_b, rl_rbp_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "stat, p = scipy.stats.ttest_ind(rl_rbp_s, rl_rbp_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "\n",
    "print('############')\n",
    "print('ERR Mean: %.3f     Std:%.3f'%(rl_err.mean(), rl_err.std())) \n",
    "print('############')\n",
    "print('lambda Mean: %.3f    Std:%.3f    kappa Mean: %.3f    Std:%.3f    AEM_ERR Mean: %.3f     Std:%.4f'%(l3s.mean(), l3s.std(), k3s.mean(), k3s.std(), rl_err_AEM.mean(), rl_err_AEM.std())) \n",
    "print('############')\n",
    "stat, p = scipy.stats.ttest_ind(rl_err, rl_err_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "\n",
    "print('############')\n",
    "print('Prec Mean: %.3f     Std:%.3f'%(rl_p.mean(), rl_p.std())) \n",
    "print('############')\n",
    "print('lambda Mean: %.3f    Std:%.3f    kappa Mean: %.3f    Std:%.3f    AEM_Prec Mean: %.3f     Std:%.4f'%(l4s.mean(), l4s.std(), k4s.mean(), k4s.std(), rl_p_AEM.mean(), rl_p_AEM.std())) \n",
    "print('############')\n",
    "stat, p = scipy.stats.ttest_ind(rl_p, rl_p_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "\n",
    "print('############')\n",
    "print('t_b Mean: %.3f    Std:%.3f    INSQ_UB Mean: %.3f     Std:%.3f    '%(t1bs.mean(), t1bs.std(),rl_insq_b.mean(), rl_insq_b.std())) \n",
    "print('############')\n",
    "print('t_s Mean: %.3f    Std:%.3f    INSQ_US Mean: %.3f     Std:%.3f   '%(t1ss.mean(), t1ss.std(), rl_insq_s.mean(), rl_insq_s.std())) \n",
    "print('############')\n",
    "print('lambda Mean: %.3f    Std:%.3f    kappa Mean: %.3f    Std:%.3f    AEM_INSQ Mean: %.3f     Std:%.4f'%(l5s.mean(), l5s.std(), k5s.mean(), k5s.std(), rl_insq_AEM.mean(), rl_insq_AEM.std())) \n",
    "print('############')\n",
    "stat, p = scipy.stats.ttest_ind(rl_insq_b, rl_insq_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "stat, p = scipy.stats.ttest_ind(rl_insq_s, rl_insq_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "\n",
    "print('############')\n",
    "print('t_b Mean: %.3f    Std:%.3f    INST_UB Mean: %.3f     Std:%.3f    '%(t2bs.mean(), t2bs.std(),rl_inst_b.mean(), rl_inst_b.std())) \n",
    "print('############')\n",
    "print('t_s Mean: %.3f    Std:%.3f    INST_US Mean: %.3f     Std:%.3f   '%(t2ss.mean(), t2ss.std(), rl_inst_s.mean(), rl_inst_s.std())) \n",
    "print('############')\n",
    "print('lambda Mean: %.3f    Std:%.3f    kappa Mean: %.3f    Std:%.3f    AEM_INST Mean: %.3f     Std:%.4f'%(l6s.mean(), l6s.std(), k6s.mean(), k6s.std(), rl_inst_AEM.mean(), rl_inst_AEM.std())) \n",
    "print('############')\n",
    "stat, p = scipy.stats.ttest_ind(rl_inst_b, rl_inst_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "stat, p = scipy.stats.ttest_ind(rl_inst_s, rl_inst_AEM)\n",
    "print('stat=%.3f, p=%.4f' % (stat, p))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "About Kappa\n",
    "'''\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_min = 0.010\n",
    "k_dcg = k1s.mean()\n",
    "k_rbp = k2s.mean()\n",
    "k_max = 0.100\n",
    "\n",
    "x = [i for i in np.arange(-1, 1, 0.01)]\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "y4 = []\n",
    "for i in x:\n",
    "    y1.append(min(1/(k_dcg + math.exp(-(1/k_dcg)*(i))), 1))\n",
    "    y2.append(min(1/(k_rbp + math.exp(-(1/k_rbp)*(i))), 1))\n",
    "    y3.append(min(1/(k_min + math.exp(-(1/k_min)*(i))), 1))\n",
    "    y4.append(min(1/(k_max + math.exp(-(1/k_max)*(i))), 1))\n",
    "    \n",
    "#plt.figure(figsize=(14, 9))\n",
    "plt.plot(x, y3, label = \"κ= %.3f\"%(k_min))\n",
    "plt.plot(x, y1, label = \"κ= %.3f\"%(k_dcg))\n",
    "plt.plot(x, y2, label = \"κ= %.3f\"%(k_rbp))\n",
    "plt.plot(x, y4, label = \"κ= %.3f\"%(k_max))\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_facecolor('#ECEBF0') # Set background-colour\n",
    "ax.spines['top'].set_visible(False) #去掉上边框\n",
    "ax.spines['bottom'].set_visible(False) #去掉下边框\n",
    "ax.spines['left'].set_visible(False) #去掉左边框\n",
    "ax.spines['right'].set_visible(False) #去掉右边框\n",
    "\n",
    "plt.grid(c='#FFFFFF')\n",
    "plt.xticks(color = \"#3c3c3c\")\n",
    "plt.yticks(color = \"#3c3c3c\")\n",
    "\n",
    "plt.xlabel('Document Quality (dq)', color = \"#3c3c3c\")\n",
    "plt.ylabel('Anchoring Effect(α)', color = \"#3c3c3c\")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('kappa-compare.png', dpi=1100, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "R with different kappa\n",
    "'''\n",
    "rbp_X = []\n",
    "rbp_Y = []\n",
    "dcg_X = []\n",
    "dcg_Y = []\n",
    "\n",
    "def search_AEM(pm, train_set, metric):\n",
    "    aem = {}\n",
    "    Y = [float(q['sat']) for q in train_set]\n",
    "    for l in np.arange(1, 1.01, 1):\n",
    "        l = round(l, 3)\n",
    "        for k in np.arange(0.01, 0.101, 0.01):\n",
    "            k = round(k, 4)\n",
    "            if metric == 'RBP':\n",
    "                X = [AEM_run(pm, l, k, q['result'], 'RBP') for q in train_set]\n",
    "            elif metric == 'DCG':\n",
    "                X = [AEM_run(pm, l, k, q['result'], 'DCG') for q in train_set]\n",
    "            if l not in aem:\n",
    "                aem[l] = {}\n",
    "            aem[l][k] = scipy.stats.spearmanr(X, Y).correlation       \n",
    "            \n",
    "    for l in aem:\n",
    "        for k in aem[l]:\n",
    "            if metric == 'RBP':\n",
    "                rbp_X.append(k)\n",
    "                rbp_Y.append(aem[l][k])\n",
    "            elif metric == 'DCG':\n",
    "                dcg_X.append(k)\n",
    "                dcg_Y.append(aem[l][k])                \n",
    "    return\n",
    "                             \n",
    "search_AEM(1.9, parsed_log, 'DCG')            \n",
    "search_AEM(0.55, parsed_log, 'RBP') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dcg_X)\n",
    "print(dcg_Y)\n",
    "print(rbp_X)\n",
    "print(rbp_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(14, 9))\n",
    "plt.plot(dcg_X, dcg_Y, label = \"DCG - b = 1.9\")\n",
    "plt.plot(rbp_X, rbp_Y, label = \"RBP - p = 0.55\")\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('#ECEBF0') # Set background-colour\n",
    "ax.spines['top'].set_visible(False) #去掉上边框\n",
    "ax.spines['bottom'].set_visible(False) #去掉下边框\n",
    "ax.spines['left'].set_visible(False) #去掉左边框\n",
    "ax.spines['right'].set_visible(False) #去掉右边框\n",
    "plt.grid(c='#FFFFFF')\n",
    "plt.xticks(color = \"#3c3c3c\")\n",
    "plt.yticks(color = \"#3c3c3c\")\n",
    "plt.xlabel('κ', color = \"#3c3c3c\")\n",
    "plt.ylabel('Spearman R', color = \"#3c3c3c\")\n",
    "plt.ylim(0.28, 0.38)\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('senstivity-compare.png', dpi=1100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_r = []\n",
    "rbp_v1 = []\n",
    "rbp_v2 = []\n",
    "dcg_v1 = []\n",
    "dcg_v2 = []\n",
    "for i in range (1, K_DEPTH_SAT+1):\n",
    "    doc_r.append(i)\n",
    "    rbp_v1.append(decay_rbp(0.85 ,i))\n",
    "    rbp_v2.append(decay_rbp(0.75 ,i))\n",
    "    dcg_v1.append(decay_dcg(1.9 ,i))\n",
    "    dcg_v2.append(decay_dcg(1.52 ,i))\n",
    "plt.plot(doc_r, rbp_v1, label = \"RBP - p = 0.85\")\n",
    "plt.plot(doc_r, rbp_v2, label = \"RBP - p = 0.75\")\n",
    "plt.plot(doc_r, dcg_v1, label = \"DCG - b = 1.9\")\n",
    "plt.plot(doc_r, dcg_v2, label = \"DCG - b = 1.52\")\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('#ECEBF0') # Set background-colour\n",
    "ax.spines['top'].set_visible(False) #去掉上边框\n",
    "ax.spines['bottom'].set_visible(False) #去掉下边框\n",
    "ax.spines['left'].set_visible(False) #去掉左边框\n",
    "ax.spines['right'].set_visible(False) #去掉右边框\n",
    "plt.grid(c='#FFFFFF')\n",
    "plt.xticks(color = \"#3c3c3c\")\n",
    "plt.yticks(color = \"#3c3c3c\")\n",
    "plt.xlabel('Document Rank', color = \"#3c3c3c\")\n",
    "plt.ylabel('Probability of User Accessing', color = \"#3c3c3c\")\n",
    "plt.legend()\n",
    "plt.savefig('rbp-compare.png', dpi=1100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
